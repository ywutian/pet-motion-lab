import torch
import os
from pathlib import Path

def check_file_size(path):
    """Ëé∑ÂèñÊñá‰ª∂ÊàñÁõÆÂΩïÂ§ßÂ∞èÔºàGBÔºâ"""
    if os.path.isfile(path):
        return os.path.getsize(path) / (1024**3)
    elif os.path.isdir(path):
        total = 0
        for dirpath, dirnames, filenames in os.walk(path):
            for f in filenames:
                fp = os.path.join(dirpath, f)
                if os.path.exists(fp):
                    total += os.path.getsize(fp)
        return total / (1024**3)
    return 0

def verify_setup():
    print("üîç È™åËØÅÊúÄ‰Ω≥Ê®°ÂûãÈÖçÁΩÆ...\n")
    
    # 1. Ê£ÄÊü• PyTorch
    print(f"‚úÖ PyTorch ÁâàÊú¨: {torch.__version__}")
    
    # 2. Ê£ÄÊü•ËÆæÂ§á
    if torch.backends.mps.is_available():
        print("‚úÖ Mac MPS (GPU) ÂèØÁî®")
        try:
            allocated = torch.mps.driver_allocated_memory() / (1024**3)
            print(f"   GPU Â∑≤ÂàÜÈÖçÂÜÖÂ≠ò: {allocated:.2f} GB")
        except:
            print("   GPU ÂÜÖÂ≠ò‰ø°ÊÅØ‰∏çÂèØÁî®")
    elif torch.cuda.is_available():
        print("‚úÖ CUDA (GPU) ÂèØÁî®")
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   GPU ÂÜÖÂ≠ò: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB")
    else:
        print("‚ö†Ô∏è Âè™Êúâ CPU ÂèØÁî®")
    
    # 3. Ê£ÄÊü•Ê®°ÂûãÊñá‰ª∂
    print("\nüì¶ Ê£ÄÊü•Ê®°ÂûãÊñá‰ª∂:\n")
    
    models = {
        "Flux.1-dev": "models/flux/flux-dev",
        "IP-Adapter (Flux)": "models/ip_adapter/flux",
        "ControlNet Union": "models/controlnet/flux-union",
        "3D Cartoon LoRA": "models/lora/flux-3d",
    }
    
    total_size = 0
    all_exist = True
    
    for name, path in models.items():
        if os.path.exists(path):
            size = check_file_size(path)
            total_size += size
            status = "‚úÖ" if size > 0.1 else "‚ö†Ô∏è"
            print(f"  {status} {name:<25} ({size:.2f} GB)")
        else:
            print(f"  ‚ùå {name:<25} (Êú™ÊâæÂà∞)")
            all_exist = False
    
    print(f"\nüìä ÊÄªÂ§ßÂ∞è: {total_size:.2f} GB")
    
    # 4. Ê£ÄÊü•‰æùËµñ
    print("\nüìö Ê£ÄÊü• Python ‰æùËµñ:\n")
    
    dependencies = [
        ("torch", "PyTorch"),
        ("diffusers", "Diffusers"),
        ("transformers", "Transformers"),
        ("accelerate", "Accelerate"),
        ("safetensors", "SafeTensors"),
        ("PIL", "Pillow"),
        ("fastapi", "FastAPI"),
        ("huggingface_hub", "HuggingFace Hub"),
    ]
    
    deps_ok = True
    for module, name in dependencies:
        try:
            __import__(module)
            print(f"  ‚úÖ {name}")
        except ImportError:
            print(f"  ‚ùå {name} (Êú™ÂÆâË£Ö)")
            deps_ok = False
            all_exist = False
    
    # 5. ÊÄªÁªì
    print("\n" + "="*60)
    if all_exist and deps_ok:
        print("‚úÖ ÊâÄÊúâÊ£ÄÊü•ÈÄöËøáÔºÅÂèØ‰ª•ÂºÄÂßã‰ΩøÁî®„ÄÇ")
        print("\nüéØ ‰∏ã‰∏ÄÊ≠•: ËøêË°åÁ§∫‰æã‰ª£Á†ÅÊµãËØïÁîüÊàê")
    else:
        print("‚ùå ÊúâÁº∫Â§±È°πÔºåËØ∑ÂÖàÂÆåÊàê‰∏ãËΩΩÂíåÂÆâË£Ö„ÄÇ")
        if not deps_ok:
            print("\nüí° ÂÆâË£Ö‰æùËµñ: pip install -r requirements.txt")
        if not all_exist:
            print("üí° ‰∏ãËΩΩÊ®°Âûã: ./download_best_models.sh")
    print("="*60)

if __name__ == "__main__":
    verify_setup()

